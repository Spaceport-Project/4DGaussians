{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "from ultralytics import YOLO\n",
    "from skimage import exposure\n",
    "\n",
    "def histogram_equalization(img):\n",
    "    img_yuv = cv2.cvtColor(img, cv2.COLOR_BGR2YUV)\n",
    "    img_yuv[:, :, 0] = cv2.equalizeHist(img_yuv[:, :, 0])\n",
    "    return cv2.cvtColor(img_yuv, cv2.COLOR_YUV2BGR)\n",
    "\n",
    "# Histogram uyumu\n",
    "def match_histograms(source, template):\n",
    "    matched = exposure.match_histograms(source, template, multichannel=True)\n",
    "    return matched\n",
    "\n",
    "def single_test():\n",
    "    img_path = \"/home/alper/Spaceport/data/internal_dataset/20_interval/1-20/original_images/cam03/images/0000.png\"\n",
    "    reference = \"/home/alper/Spaceport/data/internal_dataset/20_interval/1-20/original_images/cam05/images/0000.png\"\n",
    "\n",
    "    img = cv2.imread(img_path)\n",
    "    ref_img = cv2.imread(reference)\n",
    "\n",
    "    model = YOLO(\"yolov8x-seg.pt\")\n",
    "    results = model.predict(img_path, save=False, imgsz=1280, conf=0.1, classes=0) # 0 -> person class\n",
    "    result = results[0]\n",
    "\n",
    "    results_ref = model.predict(reference, save=False, imgsz=1280, conf=0.1, classes=0) # 0 -> person class\n",
    "    result_ref_2 = results_ref[0]\n",
    "\n",
    "    contour_ref = result_ref_2.masks.xy.pop()\n",
    "    contour_ref = contour_ref.astype(np.int32)\n",
    "    contour_ref = contour_ref.reshape(-1, 1, 2)\n",
    "\n",
    "    contour = result.masks.xy.pop()\n",
    "    contour = contour.astype(np.int32)\n",
    "    contour = contour.reshape(-1, 1, 2)\n",
    "    \n",
    "    b_mask_ref = np.zeros(ref_img.shape[:2], np.uint8)\n",
    "    _ = cv2.drawContours(b_mask_ref, [contour_ref], -1, (255, 255, 255), cv2.FILLED)\n",
    "    masked_ref = cv2.bitwise_and(ref_img, ref_img, mask=b_mask_ref)\n",
    "\n",
    "    b_mask = np.zeros(img.shape[:2], np.uint8)\n",
    "    _ = cv2.drawContours(b_mask, [contour], -1, (255, 255, 255), cv2.FILLED)\n",
    "    masked = cv2.bitwise_and(img, img, mask=b_mask)\n",
    "    equalized_image = histogram_equalization(masked)\n",
    "    matched_image = match_histograms(equalized_image, masked_ref)\n",
    "\n",
    "def main(img_path):\n",
    "    \n",
    "    reference = \"/home/alper/Spaceport/data/internal_dataset/20_interval/1-20/original_images/cam05/images/0000.png\"\n",
    "\n",
    "    img = cv2.imread(img_path)\n",
    "    ref_img = cv2.imread(reference)\n",
    "\n",
    "    model = YOLO(\"yolov8x-seg.pt\")\n",
    "    results = model.predict(img_path, save=False, imgsz=1280, conf=0.1, classes=0) # 0 -> person class\n",
    "    result = results[0]\n",
    "\n",
    "    results_ref = model.predict(reference, save=False, imgsz=1280, conf=0.1, classes=0) # 0 -> person class\n",
    "    result_ref_2 = results_ref[0]\n",
    "\n",
    "    contour_ref = result_ref_2.masks.xy.pop()\n",
    "    contour_ref = contour_ref.astype(np.int32)\n",
    "    contour_ref = contour_ref.reshape(-1, 1, 2)\n",
    "\n",
    "    contour = result.masks.xy.pop()\n",
    "    contour = contour.astype(np.int32)\n",
    "    contour = contour.reshape(-1, 1, 2)\n",
    "\n",
    "    b_mask_ref = np.zeros(ref_img.shape[:2], np.uint8)\n",
    "    _ = cv2.drawContours(b_mask_ref, [contour_ref], -1, (255, 255, 255), cv2.FILLED)\n",
    "    masked_ref = cv2.bitwise_and(ref_img, ref_img, mask=b_mask_ref)\n",
    "\n",
    "    b_mask = np.zeros(img.shape[:2], np.uint8)\n",
    "    _ = cv2.drawContours(b_mask, [contour], -1, (255, 255, 255), cv2.FILLED)\n",
    "    masked = cv2.bitwise_and(img, img, mask=b_mask)\n",
    "\n",
    "    # Uygulama\n",
    "    equalized_image = histogram_equalization(masked)\n",
    "    matched_image = match_histograms(equalized_image, masked_ref)\n",
    "\n",
    "    equalized_image = cv2.cvtColor(equalized_image, cv2.COLOR_BGR2RGB)\n",
    "    matched_image = cv2.cvtColor(matched_image, cv2.COLOR_BGR2RGB)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    masked = cv2.cvtColor(masked, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # f, axarr = plt.subplots(1,4, figsize=(40, 40))\n",
    "    # axarr[0].imshow(img)\n",
    "    # axarr[1].imshow(masked)\n",
    "    # axarr[2].imshow(equalized_image)\n",
    "    # axarr[3].imshow(matched_image)\n",
    "    # plt.imshow(img)\n",
    "    # plt.figure()\n",
    "    # plt.imshow(masked)\n",
    "    # plt.figure()\n",
    "    # plt.imshow(equalized_image)\n",
    "    # plt.figure()\n",
    "    # plt.imshow(matched_image)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # for loop\n",
    "    image_dir_path = \"/home/alper/Spaceport/data/internal_dataset/20_interval/1-20/original_images/\" #includes cam00, cam01 folders\n",
    "\n",
    "    for cam_folder in os.listdir(image_dir_path):\n",
    "        if cam_folder != \"cam05\": # cam05 is reference\n",
    "            if os.path.isdir(os.path.join(image_dir_path, cam_folder)):\n",
    "                image_directory = os.path.join(image_dir_path, cam_folder, 'images')\n",
    "                for image in sorted(os.listdir(image_directory)):\n",
    "                    if image == \"0001.png\":\n",
    "                        print(f\"Image name -> {image} on {image_directory}\")\n",
    "                        image_name = os.path.join(image_directory, image) # /home/alper/Spaceport/data/internal_dataset/20_interval/1-20/original_images/cam08/images/0002.png\n",
    "                        main(image_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## YUV Y normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "from ultralytics import YOLO\n",
    "from skimage import exposure\n",
    "\n",
    "def lighting_correction(image):\n",
    "    # Görüntüyü gri tona çevirme\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Gaussian Blur ile aydınlatma bileşenini tahmin etme\n",
    "    illumination = cv2.GaussianBlur(gray_image, (21, 21), 0)\n",
    "    \n",
    "    # Görüntüyü aydınlatma bileşeninden çıkarma\n",
    "    corrected_image = cv2.divide(gray_image, illumination, scale=255)\n",
    "    \n",
    "    # Tekrar BGR formatına çevirme\n",
    "    corrected_image_bgr = cv2.cvtColor(corrected_image, cv2.COLOR_GRAY2BGR)\n",
    "    \n",
    "    return corrected_image_bgr\n",
    "\n",
    "def seg(image):\n",
    "    model = YOLO(\"yolov8x-seg.pt\")\n",
    "    results = model.predict(image, save=False, imgsz=1280, conf=0.1, classes=0) # 0 -> person class\n",
    "    result = results[0]\n",
    "\n",
    "    contour = result.masks.xy.pop()\n",
    "    contour = contour.astype(np.int32)\n",
    "    contour = contour.reshape(-1, 1, 2)\n",
    "\n",
    "    b_mask = np.zeros(image.shape[:2], np.uint8)\n",
    "    _ = cv2.drawContours(b_mask, [contour], -1, (255, 255, 255), cv2.FILLED)\n",
    "    masked = cv2.bitwise_and(image, image, mask=b_mask)\n",
    "\n",
    "    return masked\n",
    "\n",
    "def histogram_equalization(image):\n",
    "    # Görüntüyü YUV renk uzayına çevirme\n",
    "    yuv_image = cv2.cvtColor(image, cv2.COLOR_BGR2YUV)\n",
    "    # Y kanalında histogram eşitleme\n",
    "    yuv_image[:, :, 0] = cv2.equalizeHist(yuv_image[:, :, 0])\n",
    "    # Görüntüyü tekrar BGR formatına çevirme\n",
    "    equalized_image = cv2.cvtColor(yuv_image, cv2.COLOR_YUV2BGR)\n",
    "    return equalized_image\n",
    "\n",
    "def color_normalization(image):\n",
    "    # Görüntüyü LAB renk uzayına çevirme\n",
    "    lab_image = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)\n",
    "    # LAB kanallarını ayırma\n",
    "    l, a, b = cv2.split(lab_image)\n",
    "    # LAB kanallarının ortalama ve standart sapmasını hesaplama\n",
    "    l_mean, l_std = cv2.meanStdDev(l)\n",
    "    a_mean, a_std = cv2.meanStdDev(a)\n",
    "    b_mean, b_std = cv2.meanStdDev(b)\n",
    "    # Vektörleri skalar hale getirme\n",
    "    l_mean, l_std = l_mean[0][0], l_std[0][0]\n",
    "    a_mean, a_std = a_mean[0][0], a_std[0][0]\n",
    "    b_mean, b_std = b_mean[0][0], b_std[0][0]\n",
    "    # LAB kanallarını normalize etme\n",
    "    l = np.clip((l - l_mean) / l_std * 128 + 128, 0, 255).astype(np.uint8)\n",
    "    a = np.clip((a - a_mean) / a_std * 128 + 128, 0, 255).astype(np.uint8)\n",
    "    b = np.clip((b - b_mean) / b_std * 128 + 128, 0, 255).astype(np.uint8)\n",
    "    # Normalized LAB görüntüsünü birleştirme\n",
    "    normalized_lab_image = cv2.merge((l, a, b))\n",
    "    # Görüntüyü tekrar BGR formatına çevirme\n",
    "    normalized_image = cv2.cvtColor(normalized_lab_image, cv2.COLOR_LAB2BGR)\n",
    "    return normalized_image\n",
    "\n",
    "def normalize_image(image):\n",
    "    # Histogram eşitleme\n",
    "    image = histogram_equalization(image)\n",
    "    # Renk normalizasyonu\n",
    "    # image = color_normalization(image)\n",
    "    return image\n",
    "\n",
    "img1 = cv2.imread(\"/home/alper/Spaceport/data/internal_dataset/20_interval/1-20/original_images/cam05/images/0000.png\")\n",
    "img2 = cv2.imread(\"/home/alper/Spaceport/data/internal_dataset/20_interval/1-20/original_images/cam03/images/0000.png\")\n",
    "\n",
    "# equalized_image = histogram_equalization(masked)\n",
    "\n",
    "# corrected_img = lighting_correction(img1)\n",
    "# corrected_img2 = lighting_correction(img2)\n",
    "\n",
    "masked_img1 = seg(img1)\n",
    "masked_img2 = seg(img2)\n",
    "\n",
    "normalized_image1 = normalize_image(masked_img1)\n",
    "normalized_image1_gt = normalize_image(img1)\n",
    "\n",
    "normalized_image2 = normalize_image(masked_img2)\n",
    "normalized_image2_gt = normalize_image(img2)\n",
    "\n",
    "normalized_seg1 = seg(normalized_image1_gt)\n",
    "normalized_seg2 = seg(normalized_image2_gt)\n",
    "\n",
    "# plt.imshow(cv2.cvtColor(normalized_seg1, cv2.COLOR_BGR2RGB))\n",
    "# plt.figure()\n",
    "# plt.imshow(cv2.cvtColor(normalized_seg2, cv2.COLOR_BGR2RGB))\n",
    "# plt.figure()\n",
    "\n",
    "# plt.imshow(cv2.cvtColor(normalized_image1, cv2.COLOR_BGR2RGB))\n",
    "# plt.figure()\n",
    "# plt.imshow(cv2.cvtColor(normalized_image2, cv2.COLOR_BGR2RGB))\n",
    "# plt.figure()\n",
    "\n",
    "plt.imshow(cv2.cvtColor(img1, cv2.COLOR_BGR2RGB))\n",
    "plt.figure()\n",
    "# plt.imshow(cv2.cvtColor(masked_img1, cv2.COLOR_BGR2RGB))\n",
    "# plt.figure()\n",
    "plt.imshow(cv2.cvtColor(normalized_image1_gt, cv2.COLOR_BGR2RGB))\n",
    "plt.figure()\n",
    "# plt.imshow(cv2.cvtColor(normalized_image1, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(cv2.cvtColor(img2, cv2.COLOR_BGR2RGB))\n",
    "# plt.figure()\n",
    "# plt.imshow(cv2.cvtColor(masked_img2, cv2.COLOR_BGR2RGB))\n",
    "plt.figure()\n",
    "plt.imshow(cv2.cvtColor(normalized_image2_gt, cv2.COLOR_BGR2RGB))\n",
    "# plt.figure()\n",
    "# plt.imshow(cv2.cvtColor(normalized_image2, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "# seg + hist eq\n",
    "# hist eq + seg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CLAHE after segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "from ultralytics import YOLO\n",
    "\n",
    "def show(image):\n",
    "    plt.figure()\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    plt.imshow(image)\n",
    "\n",
    "def histogram_equalization(image):\n",
    "    # Görüntüyü YUV renk uzayına çevirme\n",
    "    yuv_image = cv2.cvtColor(image, cv2.COLOR_BGR2YUV)\n",
    "    # Y kanalında histogram eşitleme\n",
    "    yuv_image[:, :, 0] = cv2.equalizeHist(yuv_image[:, :, 0])\n",
    "    # Görüntüyü tekrar BGR formatına çevirme\n",
    "    equalized_image = cv2.cvtColor(yuv_image, cv2.COLOR_YUV2BGR)\n",
    "    return equalized_image\n",
    "\n",
    "def apply_clahe(image):\n",
    "    lab = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)\n",
    "    l, a, b = cv2.split(lab)\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "    l_clahe = clahe.apply(l)\n",
    "    lab_clahe = cv2.merge((l_clahe, a, b))\n",
    "    return cv2.cvtColor(lab_clahe, cv2.COLOR_LAB2BGR)\n",
    "\n",
    "def seg(image):\n",
    "    model = YOLO(\"yolov8x-seg.pt\")\n",
    "    results = model.predict(image, save=False, imgsz=1280, conf=0.1, classes=0) # 0 -> person class\n",
    "    result = results[0]\n",
    "\n",
    "    contour = result.masks.xy.pop()\n",
    "    contour = contour.astype(np.int32)\n",
    "    contour = contour.reshape(-1, 1, 2)\n",
    "\n",
    "    b_mask = np.zeros(image.shape[:2], np.uint8)\n",
    "    _ = cv2.drawContours(b_mask, [contour], -1, (255, 255, 255), cv2.FILLED)\n",
    "    masked = cv2.bitwise_and(image, image, mask=b_mask)\n",
    "\n",
    "    return masked\n",
    "\n",
    "def adjust_gamma(image, gamma=1.0):\n",
    "    inv_gamma = 1.0 / gamma\n",
    "    table = np.array([((i / 255.0) ** inv_gamma) * 255 for i in np.arange(0, 256)]).astype(\"uint8\")\n",
    "    return cv2.LUT(image, table)\n",
    "\n",
    "def color_transfer(source, target):\n",
    "    source_lab = cv2.cvtColor(source, cv2.COLOR_BGR2LAB)\n",
    "    target_lab = cv2.cvtColor(target, cv2.COLOR_BGR2LAB)\n",
    "    \n",
    "    source_mean, source_std = cv2.meanStdDev(source_lab)\n",
    "    target_mean, target_std = cv2.meanStdDev(target_lab)\n",
    "    \n",
    "    l, a, b = cv2.split(target_lab)\n",
    "    l = (l - target_mean[0]) * (source_std[0] / target_std[0]) + source_mean[0]\n",
    "    a = (a - target_mean[1]) * (source_std[1] / target_std[1]) + source_mean[1]\n",
    "    b = (b - target_mean[2]) * (source_std[2] / target_std[2]) + source_mean[2]\n",
    "    \n",
    "    transfer_lab = cv2.merge((l, a, b))\n",
    "    transfer_bgr = cv2.cvtColor(transfer_lab.astype(np.uint8), cv2.COLOR_LAB2BGR)\n",
    "    return transfer_bgr\n",
    "\n",
    "img1 = cv2.imread(\"/home/alper/Spaceport/data/internal_dataset/20_interval/1-20/original_images/cam08/images/0000.png\")\n",
    "img2 = cv2.imread(\"/home/alper/Spaceport/data/internal_dataset/20_interval/1-20/original_images/cam12/images/0000.png\")\n",
    "\n",
    "# equalized_image = histogram_equalization(masked)\n",
    "\n",
    "# corrected_img = lighting_correction(img1)\n",
    "# corrected_img2 = lighting_correction(img2)\n",
    "\n",
    "masked_img1 = seg(img1)\n",
    "masked_img2 = seg(img2)\n",
    "\n",
    "# cv2.imwrite(\"reference_masked_image_1.png\", masked_img1)\n",
    "# normalized_image1 = histogram_equalization(masked_img1)\n",
    "# normalized_image2 = histogram_equalization(masked_img2)\n",
    "\n",
    "clahed_img1 = apply_clahe(masked_img1)\n",
    "clahed_img2 = apply_clahe(masked_img2)\n",
    "\n",
    "# image1_gamma = adjust_gamma(clahed_img1, gamma=0.3)\n",
    "# image2_gamma = adjust_gamma(clahed_img2, gamma=0.3)\n",
    "\n",
    "# new_img2 = color_transfer(masked_img1, masked_img2)\n",
    "\n",
    "show(masked_img1)\n",
    "show(clahed_img1)\n",
    "# show(clahed_img1)\n",
    "# show(image1_gamma)\n",
    "# show(masked_img2)\n",
    "show(masked_img2)\n",
    "show(clahed_img2)\n",
    "# show(normalized_image2)\n",
    "# show(clahed_img2)\n",
    "# show(image2_gamma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Color matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "from ultralytics import YOLO\n",
    "\n",
    "def match_color(source, target):\n",
    "    source_lab = cv2.cvtColor(source, cv2.COLOR_BGR2LAB)\n",
    "    target_lab = cv2.cvtColor(target, cv2.COLOR_BGR2LAB)\n",
    "    \n",
    "    l_src, a_src, b_src = cv2.split(source_lab)\n",
    "    l_tgt, a_tgt, b_tgt = cv2.split(target_lab)\n",
    "    \n",
    "    l_mean_src, a_mean_src, b_mean_src = np.mean(l_src), np.mean(a_src), np.mean(b_src)\n",
    "    l_mean_tgt, a_mean_tgt, b_mean_tgt = np.mean(l_tgt), np.mean(a_tgt), np.mean(b_tgt)\n",
    "    \n",
    "    l_tgt = l_tgt - l_mean_tgt + l_mean_src\n",
    "    a_tgt = a_tgt - a_mean_tgt + a_mean_src\n",
    "    b_tgt = b_tgt - b_mean_tgt + b_mean_src\n",
    "    \n",
    "    matched_lab = cv2.merge([l_tgt, a_tgt, b_tgt])\n",
    "    matched_bgr = cv2.cvtColor(matched_lab, cv2.COLOR_LAB2BGR)\n",
    "    \n",
    "    return matched_bgr\n",
    "\n",
    "def color_transfer(source, target):\n",
    "    source_lab = cv2.cvtColor(source, cv2.COLOR_BGR2LAB)\n",
    "    target_lab = cv2.cvtColor(target, cv2.COLOR_BGR2LAB)\n",
    "    \n",
    "    source_mean, source_std = cv2.meanStdDev(source_lab)\n",
    "    target_mean, target_std = cv2.meanStdDev(target_lab)\n",
    "    \n",
    "    l, a, b = cv2.split(target_lab)\n",
    "    l = (l - target_mean[0]) * (source_std[0] / target_std[0]) + source_mean[0]\n",
    "    a = (a - target_mean[1]) * (source_std[1] / target_std[1]) + source_mean[1]\n",
    "    b = (b - target_mean[2]) * (source_std[2] / target_std[2]) + source_mean[2]\n",
    "    \n",
    "    transfer_lab = cv2.merge((l, a, b))\n",
    "    transfer_bgr = cv2.cvtColor(transfer_lab.astype(np.uint8), cv2.COLOR_LAB2BGR)\n",
    "    return transfer_bgr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gamma corretion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "from ultralytics import YOLO\n",
    "\n",
    "def adjust_gamma(image, gamma=1.0):\n",
    "    inv_gamma = 1.0 / gamma\n",
    "    table = np.array([((i / 255.0) ** inv_gamma) * 255 for i in np.arange(0, 256)]).astype(\"uint8\")\n",
    "    return cv2.LUT(image, table)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Gaussians4D",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
